{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XmifzaRrdcEx3KoT-Ppcpa0XyDi3RebQ",
      "authorship_tag": "ABX9TyPeitEx95fcLOZobG4nBSO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriramprasath/20ITR096/blob/main/review1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udMIqnT4kryU",
        "outputId": "a651d693-a2a7-4407-9d87-841eea77076b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 'Duplication: all exons tested': 1.0\n",
            "Accuracy for 'Deletion/Duplication: boundaries known.': 1.0\n",
            "Accuracy for 'Targeted mutation testing in the patient but testing of all exons in a relative male patient': 1.0\n",
            "Accuracy for 'Clinical Diagnosis': 1.0\n",
            "Accuracy for 'Wheelchair use (if over 3 years of age)': 1.0\n",
            "Accuracy for 'Current Steroid Therapy': 1.0\n",
            "Accuracy for 'Scoliosis Surgery': 1.0\n",
            "Accuracy for 'Cardiac medication use': 1.0\n",
            "Accuracy for 'Currently included in a clinical trial': 1.0\n",
            "Accuracy for 'Currently able to sit without support': 1.0\n",
            "Accuracy for 'Heart condition': 1.0\n",
            "Accuracy for 'Echocardiogram': 1.0\n",
            "Accuracy for 'Non-invasive ventilation': 1.0\n",
            "Accuracy for 'Unnamed: 15': 1.0\n",
            "Accuracy for 'Invasive ventilation': 1.0\n",
            "Accuracy for 'Pulmonary function testing': 1.0\n",
            "Accuracy for 'Previous muscle biopsy': 1.0\n",
            "Accuracy for 'Positive family history': 1.0\n",
            "Overall Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Randomforest\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the original dataset from CSV file\n",
        "original_dataset = pd.read_csv(\"/content/muscular dystrophy edited (1).csv\")\n",
        "\n",
        "# Preprocess the data by converting \"yes\" and \"no\" to numerical values (1 and 0)\n",
        "preprocessed_dataset = original_dataset.replace({\"yes\": 1, \"no\": 0})\n",
        "\n",
        "# Save the preprocessed data to a new CSV file\n",
        "preprocessed_dataset.to_csv(\"pre.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset from CSV file\n",
        "preprocessed_dataset = pd.read_csv(\"pre.csv\")\n",
        "\n",
        "# Drop the \"Unnamed: 0\" column, which contains non-numeric values\n",
        "preprocessed_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
        "\n",
        "# Get the target columns (all columns except the first one \"Unnamed: 0\")\n",
        "target_columns = preprocessed_dataset.columns[1:]\n",
        "\n",
        "# Create an empty dictionary to store accuracies for each target\n",
        "accuracies = {}\n",
        "\n",
        "# Iterate through each target column\n",
        "for target_column in target_columns:\n",
        "    # Separate features (X) and the current target label (y)\n",
        "    X = preprocessed_dataset.drop(columns=[target_column])\n",
        "    y = preprocessed_dataset[target_column]\n",
        "\n",
        "    # Split the data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create the Random Forest classifier and fit it to the training data\n",
        "    random_forest_classifier = RandomForestClassifier(n_estimators=110, random_state=42)\n",
        "    random_forest_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = random_forest_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the classifier for the current target\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    # Store the accuracy in the dictionary with the target column name as the key\n",
        "    accuracies[target_column] = accuracy\n",
        "\n",
        "# Calculate the overall accuracy as the average of all accuracies\n",
        "overall_accuracy = sum(accuracies.values()) / len(accuracies)\n",
        "\n",
        "# Print the accuracies for each target\n",
        "for target, accuracy in accuracies.items():\n",
        "    print(f\"Accuracy for '{target}': {accuracy}\")\n",
        "\n",
        "# Print the overall accuracy as a total percentage\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5w7nYo3ejMn",
        "outputId": "9b374ec1-194e-4d45-e757-37096ed44b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyns-ZGkep5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIp7mns4lY6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from the given dataset\n",
        "data = pd.read_csv(\"/content/muscular dystrophy edited (1).csv\", index_col=0)\n",
        "\n",
        "# Calculate the total number of features for each person (excluding the name column)\n",
        "total_features = data.shape[1]\n",
        "\n",
        "# Determine the threshold (70% in this case)\n",
        "threshold = 0.7 * total_features\n",
        "\n",
        "# Initialize an empty list to store names of people meeting the criteria\n",
        "people_with_70_percent_or_more_yes = []\n",
        "\n",
        "# Iterate through the rows of the DataFrame\n",
        "for person, row in data.iterrows():\n",
        "    # Count the number of \"yes\" responses for each person\n",
        "    num_yes_responses = (row == \"yes\").sum()\n",
        "\n",
        "    # Check if the number of \"yes\" responses is 70% or more of the total features\n",
        "    if num_yes_responses >= threshold:\n",
        "        people_with_70_percent_or_more_yes.append(person)\n",
        "\n",
        "# Print the names of people who have 70% or more \"yes\" responses\n",
        "print(\"People who are suspectable as victim:\")\n",
        "for person in people_with_70_percent_or_more_yes:\n",
        "    print(person)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NNgHQ8Wlaop",
        "outputId": "99ed0676-cadf-4d81-a62b-911eee3ab39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People who are suspectable as victim:\n",
            "people a\n",
            " people d\n",
            "people j\n",
            "people a\n",
            " people d\n",
            "people j\n",
            "people a\n",
            " people d\n",
            "people j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the original dataset from CSV file\n",
        "original_dataset = pd.read_csv(\"/content/pre.csv\")\n",
        "\n",
        "# Preprocess the data by converting \"yes\" and \"no\" to numerical values (1 and 0)\n",
        "preprocessed_dataset = original_dataset.replace({\"yes\": 1, \"no\": 0})\n",
        "\n",
        "# Save the preprocessed data to a new CSV file\n",
        "preprocessed_dataset.to_csv(\"pre.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset from CSV file\n",
        "preprocessed_dataset = pd.read_csv(\"pre.csv\")\n",
        "\n",
        "# Drop the \"Unnamed: 0\" column, which contains non-numeric values\n",
        "preprocessed_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
        "\n",
        "# Get the target columns (all columns except the first one \"Unnamed: 0\")\n",
        "target_columns = preprocessed_dataset.columns[1:]\n",
        "\n",
        "# Create an empty dictionary to store accuracies for each target\n",
        "accuracies = {}\n",
        "\n",
        "# Iterate through each target column\n",
        "for target_column in target_columns:\n",
        "    # Separate features (X) and the current target label (y)\n",
        "    X = preprocessed_dataset.drop(columns=[target_column])\n",
        "    y = preprocessed_dataset[target_column]\n",
        "\n",
        "    # Split the data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create the Decision Tree classifier and fit it to the training data\n",
        "    decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "    decision_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = decision_tree_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the classifier for the current target\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    # Store the accuracy in the dictionary with the target column name as the key\n",
        "    accuracies[target_column] = accuracy\n",
        "\n",
        "# Calculate the overall accuracy as the average of all accuracies\n",
        "overall_accuracy = sum(accuracies.values()) / len(accuracies)\n",
        "\n",
        "# Print the accuracies for each target\n",
        "for target, accuracy in accuracies.items():\n",
        "    print(f\"Accuracy for '{target}': {accuracy}\")\n",
        "\n",
        "# Print the overall accuracy as a total percentage\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39fDgs-jlDVH",
        "outputId": "54dba950-a376-4276-ee80-fece2facf628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 'Duplication: all exons tested': 1.0\n",
            "Accuracy for 'Deletion/Duplication: boundaries known.': 1.0\n",
            "Accuracy for 'Targeted mutation testing in the patient but testing of all exons in a relative male patient': 1.0\n",
            "Accuracy for 'Clinical Diagnosis': 1.0\n",
            "Accuracy for 'Wheelchair use (if over 3 years of age)': 1.0\n",
            "Accuracy for 'Current Steroid Therapy': 1.0\n",
            "Accuracy for 'Scoliosis Surgery': 1.0\n",
            "Accuracy for 'Cardiac medication use': 1.0\n",
            "Accuracy for 'Currently included in a clinical trial': 1.0\n",
            "Accuracy for 'Currently able to sit without support': 1.0\n",
            "Accuracy for 'Heart condition': 1.0\n",
            "Accuracy for 'Echocardiogram': 1.0\n",
            "Accuracy for 'Non-invasive ventilation': 1.0\n",
            "Accuracy for 'Unnamed: 15': 1.0\n",
            "Accuracy for 'Invasive ventilation': 1.0\n",
            "Accuracy for 'Pulmonary function testing': 1.0\n",
            "Accuracy for 'Previous muscle biopsy': 1.0\n",
            "Accuracy for 'Positive family history': 1.0\n",
            "Overall Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# svm\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the original dataset from CSV file\n",
        "original_dataset = pd.read_csv(\"/content/pre.csv\")\n",
        "\n",
        "# Preprocess the data by converting \"yes\" and \"no\" to numerical values (1 and 0)\n",
        "preprocessed_dataset = original_dataset.replace({\"yes\": 1, \"no\": 0})\n",
        "\n",
        "# Save the preprocessed data to a new CSV file\n",
        "preprocessed_dataset.to_csv(\"pre.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset from CSV file\n",
        "preprocessed_dataset = pd.read_csv(\"pre.csv\")\n",
        "\n",
        "# Drop the \"Unnamed: 0\" column, which contains non-numeric values\n",
        "preprocessed_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
        "\n",
        "# Get the target columns (all columns except the first one \"Unnamed: 0\")\n",
        "target_columns = preprocessed_dataset.columns[1:]\n",
        "\n",
        "# Create an empty dictionary to store accuracies for each target\n",
        "accuracies = {}\n",
        "\n",
        "# Iterate through each target column\n",
        "for target_column in target_columns:\n",
        "    # Separate features (X) and the current target label (y)\n",
        "    X = preprocessed_dataset.drop(columns=[target_column])\n",
        "    y = preprocessed_dataset[target_column]\n",
        "    # print(X)\n",
        "    # print(\"break\")\n",
        "    # print(y)\n",
        "    # Split the data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "    # Calculate class weights to address class imbalance\n",
        "    class_weights = {0: (len(y_train) - y_train.sum()) / len(y_train), 1: y_train.sum() / len(y_train)}\n",
        "\n",
        "    # Create the SVM classifier and fit it to the training data\n",
        "    classifier = SVC(kernel='linear', random_state=1, class_weight=class_weights)\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the classifier for the current target\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    # Store the accuracy in the dictionary with the target column name as the key\n",
        "    accuracies[target_column] = accuracy\n",
        "\n",
        "# Calculate the overall accuracy as the average of all accuracies\n",
        "overall_accuracy = sum(accuracies.values()) / len(accuracies)\n",
        "\n",
        "# Print the accuracies for each target\n",
        "for target, accuracy in accuracies.items():\n",
        "    print(f\"Accuracy for '{target}': {accuracy}\")\n",
        "\n",
        "# Print the overall accuracy as a total percentage\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtqWy9K8lJgE",
        "outputId": "f6b29fa9-ea18-4be0-880c-31baedca0a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 'Duplication: all exons tested': 1.0\n",
            "Accuracy for 'Deletion/Duplication: boundaries known.': 1.0\n",
            "Accuracy for 'Targeted mutation testing in the patient but testing of all exons in a relative male patient': 0.8333333333333334\n",
            "Accuracy for 'Clinical Diagnosis': 0.8333333333333334\n",
            "Accuracy for 'Wheelchair use (if over 3 years of age)': 1.0\n",
            "Accuracy for 'Current Steroid Therapy': 1.0\n",
            "Accuracy for 'Scoliosis Surgery': 0.8333333333333334\n",
            "Accuracy for 'Cardiac medication use': 1.0\n",
            "Accuracy for 'Currently included in a clinical trial': 1.0\n",
            "Accuracy for 'Currently able to sit without support': 1.0\n",
            "Accuracy for 'Heart condition': 1.0\n",
            "Accuracy for 'Echocardiogram': 1.0\n",
            "Accuracy for 'Non-invasive ventilation': 1.0\n",
            "Accuracy for 'Unnamed: 15': 1.0\n",
            "Accuracy for 'Invasive ventilation': 1.0\n",
            "Accuracy for 'Pulmonary function testing': 1.0\n",
            "Accuracy for 'Previous muscle biopsy': 1.0\n",
            "Accuracy for 'Positive family history': 0.8333333333333334\n",
            "Overall Accuracy: 96.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"pre.csv\")  # Replace 'your_data_file.csv' with the actual file name\n",
        "\n",
        "# Prepare the data: Split features (X) and labels (y)\n",
        "X = data.iloc[:, 1:]  # Exclude the 'Unnamed: 0' column\n",
        "y = data.iloc[:, 0]   # First column 'Unnamed: 0' contains the labels\n",
        "\n",
        "# Introduce some random noise to the dataset\n",
        "random_noise = np.random.randint(0, 2, size=X.shape)\n",
        "X = X + random_noise\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the logistic regression model\n",
        "logistic_regression_model = LogisticRegression()\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logistic_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the overall accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60b9xdCim4zk",
        "outputId": "38a340f5-94cd-4342-b0cd-2f144c5c8d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axZ8P35gLyjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # knn\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv('/content/pre.csv')  # Replace 'your_data_file.csv' with the actual file name\n",
        "\n",
        "# Prepare the data: Split features (X) and labels (y)\n",
        "X = data.iloc[:, 1:]  # Exclude the 'Unnamed: 0' column\n",
        "y = data.iloc[:, 0]   # First column 'Unnamed: 0' contains the labels\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy using KNN: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJP-LBz8szEB",
        "outputId": "3ba73bb4-ea30-4aab-d31c-ed6f53cbf962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using KNN: 16.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosting\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"/content/pre.csv\")  # Replace 'your_data_file.csv' with the actual file name\n",
        "\n",
        "# Prepare the data: Split features (X) and labels (y)\n",
        "X = data.iloc[:, 1:]  # Exclude the 'Unnamed: 0' column\n",
        "y = data.iloc[:, 0]   # First column 'Unnamed: 0' contains the labels\n",
        "\n",
        "# Introduce some random noise to the dataset\n",
        "np.random.seed(2)\n",
        "X = X + np.random.normal(0, 0.1, size=X.shape)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Gradient Boosting classifier\n",
        "gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gradient_boosting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = gradient_boosting_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy using Gradient Boosting: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJcOmtY2tGI0",
        "outputId": "e0d9f5e6-d437-4cb1-ed95-33cad9587c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using Gradient Boosting: 33.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# naive bayes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv('/content/pre.csv')  # Replace 'your_data_file.csv' with the actual file name\n",
        "\n",
        "# Prepare the data: Split features (X) and labels (y)\n",
        "X = data.iloc[:, 1:]  # Exclude the 'Unnamed: 0' column\n",
        "y = data.iloc[:, 0]   # First column 'Unnamed: 0' contains the labels\n",
        "\n",
        "# Introduce some random noise to the dataset\n",
        "np.random.seed(6)\n",
        "X = X + np.random.normal(0, 0.1, size=X.shape)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create and train the Naive Bayes classifier\n",
        "naive_bayes_classifier = GaussianNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = naive_bayes_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy using Naive Bayes: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "Soa7P2WatYDo",
        "outputId": "fce344cf-b85d-42b2-a081-350b6ff3f231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d17a169ae316>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read the data from the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/pre.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'your_data_file.csv' with the actual file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Prepare the data: Split features (X) and labels (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pre.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "review 2\n"
      ],
      "metadata": {
        "id": "PAvo1cKPCyi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v5KbKRwWCxII"
      }
    }
  ]
}